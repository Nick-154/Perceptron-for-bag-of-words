{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "32bf19ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: svector in p:\\osu docs\\fall 2025\\machine learning\\hw_assignment1\\.venv\\lib\\site-packages (0.1.1)\n",
      "Requirement already satisfied: pyrsistent>=0.17.0 in p:\\osu docs\\fall 2025\\machine learning\\hw_assignment1\\.venv\\lib\\site-packages (from svector) (0.20.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.2 -> 25.3\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install svector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e115679f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Could not find a version that satisfies the requirement time (from versions: none)\n",
      "\n",
      "[notice] A new release of pip is available: 25.2 -> 25.3\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n",
      "ERROR: No matching distribution found for time\n"
     ]
    }
   ],
   "source": [
    "pip install time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e68b5db",
   "metadata": {},
   "outputs": [],
   "source": [
    "#PART 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "810ecf49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Could not find a version that satisfies the requirement csv (from versions: none)\n",
      "\n",
      "[notice] A new release of pip is available: 25.2 -> 25.3\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n",
      "ERROR: No matching distribution found for csv\n"
     ]
    }
   ],
   "source": [
    "pip install csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f4f937fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import time\n",
    "from svector import svector \n",
    "import csv\n",
    "\n",
    "def read_from(textfile):\n",
    "    data = pd.read_csv(textfile)\n",
    "    for i in range(len(data)):\n",
    "        id, words, label = data.iloc[i]\n",
    "        yield (1 if label==\"+\" else -1, words.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9afa0c7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_vector(words):\n",
    "    v = svector()\n",
    "    for word in words:\n",
    "        v[word] += 1\n",
    "    return v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2db56c0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#adding bias in this section\n",
    "def make_vector1(words):\n",
    "    v = svector()\n",
    "    for word in words:\n",
    "        v[word] += 1\n",
    "    # This line adds the bias term to every vector.\n",
    "    v['<bias>'] = 1\n",
    "    return v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6269ad05",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(devfile, model):\n",
    "    tot, err = 0, 0\n",
    "    for i, (label, words) in enumerate(read_from(devfile), 1): # note 1...|D|\n",
    "        err += label * (model.dot(make_vector(words))) <= 0\n",
    "    return err/i "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a43cf35b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#with make_vector bias added\n",
    "def test1(devfile, model):\n",
    "    tot, err = 0, 0\n",
    "    for i, (label, words) in enumerate(read_from(devfile), 1): # note 1...|D|\n",
    "        err += label * (model.dot(make_vector1(words))) <= 0\n",
    "    return err/i "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "95d1b8b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def train(trainfile, devfile, epochs=5):\n",
    "    t = time.time()\n",
    "    best_err = 1.\n",
    "    model = svector()\n",
    "    for it in range(1, epochs+1):\n",
    "        updates = 0\n",
    "        for i, (label, words) in enumerate(read_from(trainfile), 1): # label is +1 or -1\n",
    "            sent = make_vector(words)\n",
    "            if label * (model.dot(sent)) <= 0:\n",
    "                updates += 1\n",
    "                model += label * sent\n",
    "        dev_err = test(devfile, model)\n",
    "        best_err = min(best_err, dev_err)\n",
    "        print(\"epoch %d, update %.1f%%, dev %.1f%%\" % (it, updates / i * 100, dev_err * 100))\n",
    "    print(\"best dev err %.1f%%, |w|=%d, time: %.1f secs\" % (best_err * 100, len(model), time.time() - t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "277e4b1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#with make_vector bias added\n",
    "def train1(trainfile, devfile, epochs=5):\n",
    "    t = time.time()\n",
    "    best_err = 1.\n",
    "    model = svector()\n",
    "    for it in range(1, epochs+1):\n",
    "        updates = 0\n",
    "        for i, (label, words) in enumerate(read_from(trainfile), 1): # label is +1 or -1\n",
    "            sent = make_vector1(words)\n",
    "            if label * (model.dot(sent)) <= 0:\n",
    "                updates += 1\n",
    "                model += label * sent\n",
    "        dev_err = test1(devfile, model)\n",
    "        if dev_err < best_err:\n",
    "            best_err = dev_err\n",
    "            best_model = model.copy()\n",
    "        \n",
    "        print(\"epoch %d, update %.1f%%, dev %.1f%%\" % (it, updates / i * 100, dev_err * 100))\n",
    "    print(\"best dev err %.1f%%, |w|=%d, time: %.1f secs\" % (best_err * 100, len(model), time.time() - t))\n",
    "    \n",
    "    return best_model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6fa76821",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1, update 38.8%, dev 36.6%\n",
      "epoch 2, update 25.1%, dev 34.6%\n",
      "epoch 3, update 20.7%, dev 33.8%\n",
      "epoch 4, update 16.7%, dev 31.7%\n",
      "epoch 5, update 13.8%, dev 34.0%\n",
      "best dev err 31.7%, |w|=16743, time: 2.2 secs\n"
     ]
    }
   ],
   "source": [
    "perceptron_model1 = train('train.csv', 'dev.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ed6afb3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1, update 39.0%, dev 39.6%\n",
      "epoch 2, update 25.5%, dev 34.1%\n",
      "epoch 3, update 20.8%, dev 35.3%\n",
      "epoch 4, update 17.2%, dev 35.5%\n",
      "epoch 5, update 14.1%, dev 28.9%\n",
      "best dev err 28.9%, |w|=16744, time: 2.2 secs\n"
     ]
    }
   ],
   "source": [
    "perceptron_model2 = train1('train.csv', 'dev.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9ccec5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_predictions(test_filepath, model, output_filepath):\n",
    "\n",
    "    test_data = pd.read_csv(test_filepath)\n",
    "    # Here it will generate predictions for test_filepath\n",
    "\n",
    "\n",
    "    with open(output_filepath, \"w\") as f:\n",
    "        f.write(\"id,sentence,target\\n\")\n",
    "        for i in range(len(test_data)):\n",
    "            id_val, sentence_val, _ = test_data.iloc[i]\n",
    "            words = sentence_val.split()\n",
    "            # Using the same make_vector function that was used during training\n",
    "            vector = make_vector1(words)\n",
    "            # Predict '+' if the score is > 0, otherwise '-'\n",
    "            prediction = '+' if model.dot(vector) > 0 else '-'\n",
    "            \n",
    "            f.write(f'{id_val},\"{sentence_val}\",{prediction}\\n')\n",
    "            \n",
    "    print(f\"Submission file saved as '{output_filepath}'.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "18a1f256",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Generating predictions for 'test.csv'...\n",
      "Submission file saved as 'submission_perceptron.csv'.\n"
     ]
    }
   ],
   "source": [
    "generate_predictions('test.csv', perceptron_model2, 'submission_perceptron.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c8bacca",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d198fb0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#PART 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f1686d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q1\n",
    "def train_average(trainfile, devfile, epochs=10):\n",
    "    t = time.time()\n",
    "    best_err = 1.\n",
    "    model = svector()\n",
    "    best_model = svector() \n",
    "  \n",
    "    # `cached_model` will store the sum of all updates, scaled by when they happened.\n",
    "    cached_model = svector()\n",
    "    # `c` is counter for the total number of examples seen.\n",
    "    c = 1.0 # Using a float to make division easier \n",
    "\n",
    "    print(\"\\n Training Averaged Perceptron (with Bias)\")\n",
    "    for it in range(1, epochs+1):\n",
    "        updates = 0\n",
    "        for i, (label, words) in enumerate(read_from(trainfile), 1): \n",
    "            sent = make_vector1(words) \n",
    "            if label * (model.dot(sent)) <= 0:\n",
    "                updates += 1\n",
    "                model += label * sent\n",
    "                \n",
    "                #SMART AVERAGING UPDATE \n",
    "                cached_model += c * label * sent\n",
    "            c += 1\n",
    "\n",
    "        current_averaged_model = model - (1/c) * cached_model\n",
    "        dev_err = test1(devfile, current_averaged_model)\n",
    "        \n",
    "        if dev_err < best_err:\n",
    "            best_err = dev_err\n",
    "            # saving the averaged model, if in case this is the best error \n",
    "            best_model = current_averaged_model.copy()\n",
    "        \n",
    "        print(\"epoch %d, update %.1f%%, dev %.1f%%\" % (it, updates / i * 100, dev_err * 100))\n",
    "    print(\"best dev err %.1f%%, |w|=%d, time: %.1f secs\" % (best_err * 100, len(best_model), time.time() - t))\n",
    "    \n",
    "    return best_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "502739b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Training Averaged Perceptron (with Bias)\n",
      "epoch 1, update 39.0%, dev 31.4%\n",
      "epoch 2, update 25.5%, dev 27.7%\n",
      "epoch 3, update 20.8%, dev 27.2%\n",
      "epoch 4, update 17.2%, dev 27.6%\n",
      "epoch 5, update 14.1%, dev 27.2%\n",
      "epoch 6, update 12.2%, dev 26.7%\n",
      "epoch 7, update 10.5%, dev 26.3%\n",
      "epoch 8, update 9.7%, dev 26.4%\n",
      "epoch 9, update 7.8%, dev 26.3%\n",
      "epoch 10, update 6.9%, dev 26.3%\n",
      "best dev err 26.3%, |w|=16744, time: 4.6 secs\n"
     ]
    }
   ],
   "source": [
    "perceptron_model3 = train_average('train.csv', 'dev.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "db64d3ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "#PART 2 Question 3\n",
    "#Prints the top 20 positive sen\n",
    "def get_pos_features(model, dev_file):\n",
    "    sentence_score = []\n",
    "    dev_data = pd.read_csv(dev_file)\n",
    "\n",
    "    for i in range(len(dev_data)):\n",
    "        _id, sentence, _ = dev_data.iloc[i]\n",
    "        words = sentence.split()\n",
    "        vector = make_vector1(words) \n",
    "        score = model.dot(vector)\n",
    "        sentence_score.append({'sentence': sentence, 'score': score})\n",
    "    sorted_sentences = sorted(sentence_score, key=lambda item: item['score'], reverse=True)\n",
    "    \n",
    "    print(\"\\nTop 20 Positively Scored Sentences in Dev Data based on my perceptron model: \")\n",
    "    for item in sorted_sentences[:20]:\n",
    "        print(f\"Score: {item['score']:.4f} | Sentence: {item['sentence']}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4504c44c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Top 20 Positively Scored Sentences in Dev Data based on my perceptron model: \n",
      "Score: 40.8533 | Sentence: witty dialog between realistic characters showing honest emotions it 's touching and tender and proves that even in sorrow you can find humor like blended shades of lipstick , these components combine into one terrific story with lots of laughs\n",
      "Score: 39.8136 | Sentence: both a beautifully made nature film and a tribute to a woman whose passion for this region and its inhabitants still shines in her quiet blue eyes\n",
      "Score: 38.3537 | Sentence: a delightfully unpredictable , hilarious comedy with wonderful performances that tug at your heart in ways that utterly transcend gender labels\n",
      "Score: 37.5523 | Sentence: a journey spanning nearly three decades of bittersweet camaraderie and history , in which we feel that we truly know what makes holly and marina tick , and our hearts go out to them as both continue to negotiate their imperfect , love hate relationship\n",
      "Score: 37.5249 | Sentence: an enjoyable comedy of lingual and cultural differences the ch teau is a film full of life and small delights that has all the wiggling energy of young kitten\n",
      "Score: 37.5004 | Sentence: delia , greta , and paula rank as three of the most multilayered and sympathetic female characters of the year as each of them searches for their place in the world , miller digs into their very minds to find an unblinking , flawed humanity\n",
      "Score: 36.6724 | Sentence: is funny in the way that makes you ache with sadness ( the way chekhov is funny ) , profound without ever being self important , warm without ever succumbing to sentimentality\n",
      "Score: 36.5419 | Sentence: art house to the core , read my lips is a genre curling crime story that revives the free wheeling noir spirit of old french cinema\n",
      "Score: 36.2482 | Sentence: it 's worth the extra effort to see an artist , still committed to growth in his ninth decade , change while remaining true to his principles with a film whose very subject is , quite pointedly , about the peril of such efforts\n",
      "Score: 35.1679 | Sentence: on guard ! wo n't be placed in the pantheon of the best of the swashbucklers but it is a whole lot of fun and you get to see the one of the world 's best actors , daniel auteuil , have a whale of a good time\n",
      "Score: 35.1501 | Sentence: about schmidt belongs to nicholson gone are the flamboyant mannerisms that are the trademark of several of his performances as schmidt , nicholson walks with a slow , deliberate gait , chooses his words carefully and subdues his natural exuberance\n",
      "Score: 34.3123 | Sentence: the fourth pokemon is a diverting if predictable adventure suitable for a matinee , with a message that cautions children about disturbing the world 's delicate ecological balance\n",
      "Score: 33.8953 | Sentence: a compelling french psychological drama examining the encounter of an aloof father and his chilly son after 20 years apart\n",
      "Score: 32.9814 | Sentence: both garcia and jagger turn in perfectly executed and wonderfully sympathetic characters , who are alternately touching and funny\n",
      "Score: 32.8574 | Sentence: the determination of pinochet 's victims to seek justice , and their often heartbreaking testimony , spoken directly into director patricio guzman 's camera , pack a powerful emotional wallop\n",
      "Score: 32.4355 | Sentence: ` alice 's adventure through the looking glass and into zombie land ' is filled with strange and wonderful creatures\n",
      "Score: 31.8714 | Sentence: it 's sweet it 's funny it wears its heart on the sleeve of its gaudy hawaiian shirt and , thanks to the presence of ` the king , ' it also rocks\n",
      "Score: 31.6748 | Sentence: a small gem of a movie that defies classification and is as thought provoking as it is funny , scary and sad\n",
      "Score: 31.6598 | Sentence: this is a gorgeous film vivid with color , music and life delight your senses and crash this wedding !\n",
      "Score: 31.3300 | Sentence: to some eyes this will seem like a recycling of clich s , an assassin 's greatest hits to others , it will remind them that hong kong action cinema is still alive and kicking\n"
     ]
    }
   ],
   "source": [
    "top_pos= get_pos_features(perceptron_model3,'dev.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b61d091e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_pos_sen_to_csv(model, dev_file, output_filepath):\n",
    "    sentence_score = []\n",
    "    dev_data = pd.read_csv(dev_file)\n",
    "\n",
    "    for i in range(len(dev_data)):\n",
    "        _id, sentence, _ = dev_data.iloc[i]\n",
    "        words = sentence.split()\n",
    "        vector = make_vector1(words) \n",
    "        score = model.dot(vector)\n",
    "        sentence_score.append({'sentence': sentence, 'score': score})\n",
    "        \n",
    "    sorted_sentences = sorted(sentence_score, key=lambda item: item['score'], reverse=True)\n",
    "\n",
    "   # Here it will generate predictions for output_filepath\n",
    "\n",
    "    with open(output_filepath, 'w', newline='', encoding='utf-8') as csvfile:\n",
    "        fieldnames = ['score', 'sentence']\n",
    "        writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
    "        writer.writeheader()\n",
    "        for item in sorted_sentences[:60]:\n",
    "            writer.writerow({'score': f\"{item['score']:.4f}\", 'sentence': item['sentence']})\n",
    "    print(f\"Submission file saved as '{output_filepath}'.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9e2a56be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Saving all positively sorted sentences to 'most_pos_sentences.csv'...\n",
      "Submission file saved as 'most_pos_sentences.csv'.\n"
     ]
    }
   ],
   "source": [
    "save_pos_sen_to_csv(perceptron_model3,'dev.csv','most_pos_sentences.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3c2c53f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Prints the top 20 negative sentences\n",
    "def get_neg_features(model,dev_file): \n",
    "\n",
    "    sentence_score = []\n",
    "    dev_data = pd.read_csv(dev_file)\n",
    "\n",
    "    for i in range(len(dev_data)):\n",
    "        _id, sentence, _ = dev_data.iloc[i]\n",
    "        words = sentence.split()\n",
    "        vector = make_vector1(words)\n",
    "        score = model.dot(vector)\n",
    "        sentence_score.append({'sentence': sentence, 'score': score})\n",
    "    sorted_sentences = sorted(sentence_score, key=lambda item: item['score'])\n",
    "\n",
    "    print(\"\\nTop 20 Most Negatively Scored Sentences in Dev Data based on my perceptron model\")\n",
    "    for item in sorted_sentences[:20]:\n",
    "        print(f\"Score: {item['score']:.4f} | Sentence: {item['sentence']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ebe1eb88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Top 20 Most Negatively Scored Sentences in Dev Data based on my perceptron model\n",
      "Score: -55.3830 | Sentence: it 's not too fast and not too slow it 's not too racy and it 's not too offensive it 's not too much of anything\n",
      "Score: -50.1244 | Sentence: the script was reportedly rewritten a dozen times either 11 times too many or else too few\n",
      "Score: -43.6594 | Sentence: hawke 's film , a boring , pretentious waste of nearly two hours , does n't tell you anything except that the chelsea hotel today is populated by whiny , pathetic , starving and untalented artistes\n",
      "Score: -42.0801 | Sentence: the script feels as if it started to explore the obvious voyeuristic potential of ` hypertime ' but then backed off when the producers saw the grosses for spy kids\n",
      "Score: -41.1777 | Sentence: the thing about guys like evans is this you 're never quite sure where self promotion ends and the truth begins but as you watch the movie , you 're too interested to care\n",
      "Score: -38.5063 | Sentence: resurrection has the dubious distinction of being a really bad imitation of the really bad blair witch project\n",
      "Score: -38.0982 | Sentence: i 'm not sure which is worse the poor acting by the ensemble cast , the flat dialogue by vincent r nebrida or the gutless direction by laurice guillen\n",
      "Score: -36.8217 | Sentence: the film 's final hour , where nearly all the previous unseen material resides , is unconvincing soap opera that tornatore was right to cut\n",
      "Score: -35.8159 | Sentence: the following things are not at all entertaining the bad sound , the lack of climax and , worst of all , watching seinfeld ( who is also one of the film 's producers ) do everything he can to look like a good guy\n",
      "Score: -35.0821 | Sentence: poor ben bratt could n't find stardom if mapquest emailed him point to point driving directions\n",
      "Score: -34.9700 | Sentence: neither the funniest film that eddie murphy nor robert de niro has ever made , showtime is nevertheless efficiently amusing for a good while before it collapses into exactly the kind of buddy cop comedy it set out to lampoon , anyway\n",
      "Score: -34.1428 | Sentence: what 's the most positive thing that can be said about the new rob schneider vehicle ? well , it 's not as pathetic as the animal\n",
      "Score: -33.3487 | Sentence: davis the performer is plenty fetching enough , but she needs to shake up the mix , and work in something that does n't feel like a half baked stand up routine\n",
      "Score: -33.1102 | Sentence: instead of trying to bust some blondes , diggs should be probing why a guy with his talent ended up in a movie this bad\n",
      "Score: -33.0263 | Sentence: the pace of the film is very slow ( for obvious reasons ) and that too becomes off putting\n",
      "Score: -32.8740 | Sentence: curiously , super troopers suffers because it does n't have enough vices to merit its 103 minute length\n",
      "Score: -32.0171 | Sentence: yet another genre exercise , gangster no 1 is as generic as its title\n",
      "Score: -31.8311 | Sentence: so verbally flatfooted and so emotionally predictable or bland that it plays like the standard made for tv movie\n",
      "Score: -30.9668 | Sentence: it 's absolutely amazing how first time director kevin donovan managed to find something new to add to the canon of chan make chan 's action sequences boring\n",
      "Score: -30.7149 | Sentence: the film was produced by jerry bruckheimer and directed by joel schumacher , and reflects the worst of their shallow styles wildly overproduced , inadequately motivated every step of the way and demographically targeted to please every one ( and no one )\n"
     ]
    }
   ],
   "source": [
    "top_neg= get_neg_features(perceptron_model3,'dev.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66fc131d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_neg_to_csv(model, dev_file, output_filepath):\n",
    "    sentence_score = []\n",
    "    dev_data = pd.read_csv(dev_file)\n",
    "\n",
    "    for i in range(len(dev_data)):\n",
    "        _id, sentence, _ = dev_data.iloc[i]\n",
    "        words = sentence.split()\n",
    "        vector = make_vector1(words) \n",
    "        score = model.dot(vector)\n",
    "        sentence_score.append({'sentence': sentence, 'score': score})\n",
    "        \n",
    "    sorted_sentences = sorted(sentence_score, key=lambda item: item['score'])\n",
    "\n",
    "    # Here it will generate predictions for output_filepath\n",
    "\n",
    "    with open(output_filepath, 'w', newline='', encoding='utf-8') as csvfile:\n",
    "        fieldnames = ['score', 'sentence']\n",
    "        writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
    "        writer.writeheader()\n",
    "        for item in sorted_sentences[:60]:\n",
    "            writer.writerow({'score': f\"{item['score']:.4f}\", 'sentence': item['sentence']})\n",
    "    print(f\"Submission file saved as '{output_filepath}'.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "addfe05f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Saving all negitively sorted sentences to 'most_neg_sentences.csv'...\n",
      "Submission file saved as 'most_neg_sentences.csv'.\n"
     ]
    }
   ],
   "source": [
    "save_neg_to_csv(perceptron_model3,'dev.csv','most_neg_sentences.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adff8ba7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#testing my perceptron_model3 on test dataset\n",
    "def generate_prediction_avg(test_filepath, model, output_filepath):\n",
    "    test_data = pd.read_csv(test_filepath)\n",
    "   # Here it will generate predictions for test_filepath\n",
    "\n",
    "\n",
    "    with open(output_filepath, \"w\", newline='', encoding='utf-8') as f:\n",
    "        # Write the required CSV header\n",
    "        f.write(\"id,sentence,target\\n\")\n",
    "        \n",
    "        for i in range(len(test_data)):\n",
    "            id_val, sentence_val, _ = test_data.iloc[i]\n",
    "            words = sentence_val.split()\n",
    "            vector = make_vector1(words)\n",
    "            prediction = '+' if model.dot(vector) > 0 else '-'\n",
    "            f.write(f'{id_val},\"{sentence_val}\",{prediction}\\n')\n",
    "            \n",
    "    print(f\"Submission file saved as '{output_filepath}'.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5f751d83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Generating predictions for 'test.csv'...\n",
      "Submission file saved as 'submission_perceptron.csv'.\n"
     ]
    }
   ],
   "source": [
    "generate_prediction_avg('test.csv', perceptron_model3, 'submission_perceptron.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "2ed94ce5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#PART 3\n",
    "# Creating vector-creation functin for training the pruned data \n",
    "def make_vectorp(words, vocab=None):\n",
    "    v = svector()\n",
    "    for word in words:\n",
    "        if vocab is None or word in vocab:\n",
    "            v[word] += 1\n",
    "    v['<bias>'] = 1\n",
    "    return v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "02b56a4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating testing function for pruned data \n",
    "def testp(devfile, model, vocab=None):\n",
    "    err = 0\n",
    "    total = 0\n",
    "    for label, words in read_from(devfile):\n",
    "        total += 1\n",
    "        vector = make_vectorp(words, vocab)\n",
    "        err += label * (model.dot(vector)) <= 0\n",
    "    return err / total\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "6fce52af",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_average_pruned(trainfile, devfile, epochs=10, prune_threshold=1):\n",
    "    t_start = time.time()\n",
    "    \n",
    "   # Building vocabulary by pruning words with count <= 1 as I have set in prune_threshold\n",
    "    vocab_counts = {}\n",
    "    for _, words in read_from(trainfile):\n",
    "        for word in words:\n",
    "            vocab_counts[word] = vocab_counts.get(word, 0) + 1\n",
    "    pruned_vocab = {word for word, count in vocab_counts.items() if count > prune_threshold}\n",
    "    print(f\"Original vocab size: {len(vocab_counts)}, Pruned vocab size: {len(pruned_vocab)}\")\n",
    "    \n",
    "    # Train using existing functions, now passing pruned_vocab dictionary\n",
    "    best_err = 1.\n",
    "    model = svector()\n",
    "    cached_model = svector()\n",
    "    c = 1.0\n",
    "    best_model = svector()\n",
    "\n",
    "    # Training Averaged Perceptron using Pruned data\n",
    "    for z in range(1, epochs + 1):\n",
    "        updates = 0\n",
    "        for i, (label, words) in enumerate(read_from(trainfile), 1):\n",
    "            sent = make_vectorp(words, pruned_vocab)\n",
    "            if label * (model.dot(sent)) <= 0:\n",
    "                updates += 1\n",
    "                model += label * sent\n",
    "                cached_model += c * label * sent\n",
    "            c += 1\n",
    "\n",
    "        current_averaged_model = model - (1/c) * cached_model\n",
    "\n",
    "    #Calculating the dev error now\n",
    "        dev_err = testp(devfile, current_averaged_model, pruned_vocab)\n",
    "        if dev_err < best_err:\n",
    "            best_err = dev_err\n",
    "            best_model = current_averaged_model.copy()\n",
    "        \n",
    "        print(\"epoch %d, update %.1f%%, dev %.1f%%\" % (z, updates / i * 100, dev_err * 100))\n",
    "        \n",
    "    print(\"best dev err %.1f%%, |w|=%d, time: %.1f secs\" % (best_err * 100, len(best_model), time.time() - t_start))\n",
    "    \n",
    "    return best_model, pruned_vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "ff3ffb1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original vocab size: 15805, Pruned vocab size: 8424\n",
      "epoch 1, update 39.0%, dev 31.6%\n",
      "epoch 2, update 26.4%, dev 27.5%\n",
      "epoch 3, update 22.8%, dev 26.8%\n",
      "epoch 4, update 18.8%, dev 26.6%\n",
      "epoch 5, update 17.2%, dev 25.9%\n",
      "epoch 6, update 14.8%, dev 26.5%\n",
      "epoch 7, update 13.2%, dev 27.0%\n",
      "epoch 8, update 12.7%, dev 26.7%\n",
      "epoch 9, update 11.4%, dev 26.6%\n",
      "epoch 10, update 10.6%, dev 26.2%\n",
      "best dev err 25.9%, |w|=8425, time: 4.9 secs\n"
     ]
    }
   ],
   "source": [
    "Prune_model , vocab_1 = train_average_pruned('train.csv', 'dev.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ad9d5de",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89680592",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05ae26a2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7f47fbd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4cd4168d",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jupyterkernel",
   "language": "python",
   "name": "jupyterkernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
